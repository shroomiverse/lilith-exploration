# Lilith: An Exploration in Divergence-Aware Optimization
Status: Work in Progress — Open to Collaboration

Lilith is not a finished algorithm. It’s a research exploration into whether an optimizer can adapt its own learning strategy when progress stalls — without destabilizing training.

Inspired by:
- Gradient-based optimizers (e.g., Adam, RMSProp)
- Exploration/exploitation strategies from multi-armed bandits
- Mutation and adaptation from evolutionary theory
- Human learning parallels: reflection, divergence, course-correction

Goals
- Experiment with divergence-aware triggers in optimizer logic
- Test whether controlled mutation can aid adaptation safely
- Invite feedback, critique, and collaboration

How to engage
- Open an issue with ideas, critiques, or questions
- Share tiny experiments or pseudocode in issues or PRs

Related Work
See related_work.md for citations that informed this exploration.

License
MIT — free to use, modify, and build upon.
